{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Import Libraries\n",
    "\n",
    "We begin by importing the required Python libraries:\n",
    "- `os` for file and directory handling.\n",
    "- `re` for regular expressions, used in text cleaning.\n",
    "- `defaultdict` from `collections` for counting trigrams efficiently.\n",
    "\n",
    "These libraries are standard and require no external installation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "from collections import  defaultdict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define `sanitizeText` Function\n",
    "\n",
    "### Purpose\n",
    "This function takes raw text from Project Gutenberg and:\n",
    "1. Removes the preamble (content before the main text) using the marker `*** START OF THIS PROJECT GUTENBERG EBOOK ***`.\n",
    "2. Removes the postamble (content after the main text) using the marker `*** END OF THIS PROJECT GUTENBERG EBOOK ***`.\n",
    "3. Removes unwanted characters, leaving only uppercase letters, spaces, and full stops.\n",
    "4. Converts the cleaned text to uppercase for consistency.\n",
    "\n",
    "### Why is this step important?\n",
    "Cleaning the text ensures our trigram model is based solely on meaningful characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitizeText(text):\n",
    "    \"\"\"\n",
    "    Cleans the input text by removing preamble, postamble, and unwanted characters.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The raw text.\n",
    "\n",
    "    Returns:\n",
    "    str: The sanitized text.\n",
    "    \"\"\"\n",
    "    # Remove preamble\n",
    "    start_marker = '*** START OF THIS PROJECT GUTENBERG EBOOK ***'\n",
    "    end_marker = '*** END OF THIS PROJECT GUTENBERG EBOOK ***'\n",
    "    start_index = text.find(start_marker)\n",
    "    end_index = text.find(end_marker)\n",
    "    if start_index != -1:\n",
    "        text = text[start_index + len(start_marker):]\n",
    "    if end_index != -1:\n",
    "        text = text[:end_index]\n",
    "\n",
    "    # Remove unwanted characters\n",
    "    text = re.sub(r'[^A-Z\\s\\.]', '', text.upper())\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load and Clean All Texts\n",
    "\n",
    "### Purpose\n",
    "This function loops through all `.txt` files in a given folder, applies the `sanitizeText` function to clean each file, and combines all the cleaned texts into a single corpus.\n",
    "\n",
    "### Why is this step important?\n",
    "Using multiple text files increases the dataset size, making the trigram model more accurate and representative of the English language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read and sanitized Dracula.txt\n",
      "First 500 characters of cleaned text from Dracula.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF DRACULA\n",
      "    \n",
      "THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES AND\n",
      "MOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONS\n",
      "WHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMS\n",
      "OF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINE\n",
      "AT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATES\n",
      "YOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATED\n",
      "BEFORE USING THIS EBOOK.\n",
      "\n",
      "TITLE DRACULA\n",
      "\n",
      "\n",
      "\n",
      "Successfully read and sanitized Frankenstein.txt\n",
      "First 500 characters of cleaned text from Frankenstein.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF FRANKENSTEIN OR THE MODERN PROMETHEUS\n",
      "    \n",
      "THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES AND\n",
      "MOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONS\n",
      "WHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMS\n",
      "OF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINE\n",
      "AT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATES\n",
      "YOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATED\n",
      "BEFORE USIN\n",
      "\n",
      "Successfully read and sanitized Leviathan.txt\n",
      "First 500 characters of cleaned text from Leviathan.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF LEVIATHAN\n",
      "    \n",
      "THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES AND\n",
      "MOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONS\n",
      "WHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMS\n",
      "OF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINE\n",
      "AT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATES\n",
      "YOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATED\n",
      "BEFORE USING THIS EBOOK.\n",
      "\n",
      "TITLE LEVIATH\n",
      "\n",
      "Successfully read and sanitized MobyDick.txt\n",
      "First 500 characters of cleaned text from MobyDick.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF MOBY DICK OR THE WHALE\n",
      "    \n",
      "THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES AND\n",
      "MOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONS\n",
      "WHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMS\n",
      "OF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINE\n",
      "AT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATES\n",
      "YOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATED\n",
      "BEFORE USING THIS EBOOK.\n",
      "\n",
      "\n",
      "\n",
      "Successfully read and sanitized RomeoJuliet.txt\n",
      "First 500 characters of cleaned text from RomeoJuliet.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF ROMEO AND JULIET\n",
      "    \n",
      "THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES AND\n",
      "MOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONS\n",
      "WHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMS\n",
      "OF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINE\n",
      "AT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATES\n",
      "YOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATED\n",
      "BEFORE USING THIS EBOOK.\n",
      "\n",
      "TITLE \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_and_clean_texts(folder_path):\n",
    "    \"\"\"\n",
    "    Reads and sanitizes all text files in the given folder.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): Path to the folder containing the text files.\n",
    "\n",
    "    Returns:\n",
    "    str: Combined and cleaned text from all files.\n",
    "    \"\"\"\n",
    "    all_text = \"\"\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):  # Only process .txt files\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                sanitized_text = sanitizeText(text)\n",
    "                all_text += sanitized_text\n",
    "                print(f\"Successfully read and sanitized {filename}\")\n",
    "                print(f\"First 500 characters of cleaned text from {filename}:\\n{sanitized_text[:500]}\\n\")\n",
    "    return all_text\n",
    "\n",
    "# Path to the folder with text files\n",
    "folder_path = 'Texts/'\n",
    "\n",
    "# Load and clean texts\n",
    "corpus = load_and_clean_texts(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build the Trigram Model\n",
    "\n",
    "### Purpose\n",
    "This function processes the cleaned text to create a trigram model. The model counts the occurrences of each sequence of three characters.\n",
    "\n",
    "### Why is this step important?\n",
    "The trigram model is the core of this task. It represents the structure and frequency of character sequences in the dataset.\n",
    "\n",
    "### Key Details\n",
    "- A dictionary is used to store trigrams as keys and their counts as values.\n",
    "- `defaultdict` is used to handle missing keys automatically.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 trigrams and their counts:\n",
      "THE: 64225\n",
      "HE : 46529\n",
      "E P: 5443\n",
      " PR: 5517\n",
      "PRO: 3571\n",
      "ROJ: 469\n",
      "OJE: 469\n",
      "JEC: 1262\n",
      "ECT: 3300\n",
      "CT : 1852\n"
     ]
    }
   ],
   "source": [
    "def build_trigram_model(text):\n",
    "    \"\"\"\n",
    "    Creates a trigram model by counting the occurrences of each trigram.\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): The cleaned text.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary where keys are trigrams and values are their counts.\n",
    "    \"\"\"\n",
    "    trigram_model = {}  # Initialize an empty dictionary\n",
    "    \n",
    "    # Iterate through the text to extract trigrams\n",
    "    for i in range(len(text) - 2):\n",
    "        trigram = text[i:i + 3]  # Extract three consecutive characters\n",
    "        if trigram in trigram_model:\n",
    "            trigram_model[trigram] += 1  # Increment count if trigram exists\n",
    "        else:\n",
    "            trigram_model[trigram] = 1  # Initialize count if trigram is new\n",
    "    \n",
    "    return trigram_model\n",
    "\n",
    "# Build the trigram model\n",
    "trigram_model = build_trigram_model(corpus)\n",
    "\n",
    "# Display the first 10 trigrams for inspection\n",
    "print(\"First 10 trigrams and their counts:\")\n",
    "for trigram, count in list(trigram_model.items())[:10]:\n",
    "    print(f\"{trigram}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 5: Save the Trigram Model to a JSON File\n",
    "\n",
    "### Purpose\n",
    "This step involves saving the trigram model, which is a dictionary of trigram counts, to a JSON file. This allows for easy storage and retrieval of the model for future use.\n",
    "\n",
    "### Why is this step important?\n",
    "Saving the trigram model ensures that the data can be reused without needing to rebuild the model from scratch. This is particularly useful for large datasets where rebuilding the model can be time-consuming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Save the trigram model to a JSON file\n",
    "# def save_trigram_model_to_json(trigrams, output_file):\n",
    "#     \"\"\"\n",
    "#     Saves the trigram model to a JSON file.\n",
    "\n",
    "#     Parameters:\n",
    "#     trigrams (dict): Dictionary of trigram counts.\n",
    "#     output_file (str): Path to the output JSON file.\n",
    "#     \"\"\"\n",
    "#     with open(output_file, 'w') as file:\n",
    "#         json.dump(trigrams, file, indent=4)  # Use `indent=4` for pretty printing\n",
    "\n",
    "# # Save to JSON file after processing all texts\n",
    "# output_json_file = 'trigram_model.json'\n",
    "# save_trigram_model_to_json(trigram_model, output_json_file)\n",
    "# print(f\"Trigram model saved to {output_json_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Generate Text Using the Trigram Model\n",
    "\n",
    "### Objective\n",
    "\n",
    "Task 2 involves generating a 10,000 character text based off the original trigram model that I previously created in Task1. \n",
    "\n",
    "This involves: \n",
    "| Step | Description |\n",
    "|------|-------------|\n",
    "| **1** | Starting with the inital string `TH` |\n",
    "| **2**| Generating each next character by looking at the previous two. |\n",
    "| **3** | Finding the trigrams in my model that start with those two characters.|\n",
    "| **4** | Randomly select one of the third letters of those trigrams using the counts as weights|\n",
    "\n",
    "\n",
    "\n",
    "### Implementation\n",
    "The implementation is split into:\n",
    "1. A function to generate text using the trigram model.\n",
    "2. Saving the generated text to a file for further inspection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_text(trigram_model, initial_text=\"TH\", length=10000):\n",
    "   \n",
    "    \n",
    "    # initialize the generated text\n",
    "    generated_text = initial_text\n",
    "    \n",
    "    while len(generated_text) < length:\n",
    "        # get the last two characters\n",
    "        last_two = generated_text[-2:]\n",
    "        \n",
    "        # find possible trigrams\n",
    "        potential_trigrams = [\n",
    "            (trigram[2], count) for trigram, count in trigram_model.items() if trigram.startswith(last_two)\n",
    "        ]\n",
    "        \n",
    "        # if no matching trigram, stop generation\n",
    "        if not potential_trigrams:\n",
    "            print(\"No matching trigrams found. Ending generation early.\")\n",
    "            break\n",
    "        \n",
    "        # extract letters and their weights\n",
    "        letters, weights = zip(*potential_trigrams)\n",
    "        \n",
    "        # choose the next character based on weights\n",
    "        next_char = random.choices(letters, weights=weights, k=1)[0]\n",
    "        \n",
    "        # add the next character to the text\n",
    "        generated_text += next_char\n",
    "\n",
    "        \n",
    "    \n",
    "    return generated_text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "| Step | Description |\n",
    "|------|-------------|\n",
    "| **1. Loop Until Length Reached** | The loop continues until the generated text reaches the specified length. |\n",
    "| **2. Find Matching Trigrams** | Filters the trigram dictionary to find entries starting with the last two characters. |\n",
    "| **3. Select Next Character** | Chooses the next character based on the most frequent trigram. [Python's `max()` Function Documentation](https://docs.python.org/3/library/functions.html#max) |\n",
    "| **4. String Manipulation** | [Python String Slicing](https://python-reference.readthedocs.io/en/latest/docs/brackets/slicing.html) [Appending Characters to Strings](https://stackoverflow.com/a/38729603) |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
