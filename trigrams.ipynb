{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Import Libraries\n",
    "\n",
    "We begin by importing the required Python libraries:\n",
    "- `os` for file and directory handling.\n",
    "- `re` for regular expressions, used in text cleaning.\n",
    "- `defaultdict` from `collections` for counting trigrams efficiently.\n",
    "\n",
    "These libraries are standard and require no external installation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from collections import  defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define `sanitizeText` Function\n",
    "\n",
    "### Purpose\n",
    "This function takes raw text from Project Gutenberg and:\n",
    "1. Removes the preamble (content before the main text) using the marker `*** START OF THIS PROJECT GUTENBERG EBOOK ***`.\n",
    "2. Removes the postamble (content after the main text) using the marker `*** END OF THIS PROJECT GUTENBERG EBOOK ***`.\n",
    "3. Removes unwanted characters, leaving only uppercase letters, spaces, and full stops.\n",
    "4. Converts the cleaned text to uppercase for consistency.\n",
    "\n",
    "### Why is this step important?\n",
    "Cleaning the text ensures our trigram model is based solely on meaningful characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitizeText(text):\n",
    "    \"\"\"\n",
    "    Cleans the input text by removing preamble, postamble, and unwanted characters.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The raw text.\n",
    "\n",
    "    Returns:\n",
    "    str: The sanitized text.\n",
    "    \"\"\"\n",
    "    # Remove preamble\n",
    "    start_marker = '*** START OF THIS PROJECT GUTENBERG EBOOK ***'\n",
    "    end_marker = '*** END OF THIS PROJECT GUTENBERG EBOOK ***'\n",
    "    start_index = text.find(start_marker)\n",
    "    end_index = text.find(end_marker)\n",
    "    if start_index != -1:\n",
    "        text = text[start_index + len(start_marker):]\n",
    "    if end_index != -1:\n",
    "        text = text[:end_index]\n",
    "\n",
    "    # Remove unwanted characters\n",
    "    text = re.sub(r'[^A-Z\\s\\.]', '', text.upper())\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load and Clean All Texts\n",
    "\n",
    "### Purpose\n",
    "This function loops through all `.txt` files in a given folder, applies the `sanitizeText` function to clean each file, and combines all the cleaned texts into a single corpus.\n",
    "\n",
    "### Why is this step important?\n",
    "Using multiple text files increases the dataset size, making the trigram model more accurate and representative of the English language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read and sanitized Dracula.txt\n",
      "First 500 characters of cleaned text from Dracula.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF DRACULA\n",
      "    \n",
      "THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES AND\n",
      "MOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONS\n",
      "WHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMS\n",
      "OF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINE\n",
      "AT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATES\n",
      "YOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATED\n",
      "BEFORE USING THIS EBOOK.\n",
      "\n",
      "TITLE DRACULA\n",
      "\n",
      "\n",
      "\n",
      "Successfully read and sanitized Frankenstein.txt\n",
      "First 500 characters of cleaned text from Frankenstein.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF FRANKENSTEIN OR THE MODERN PROMETHEUS\n",
      "    \n",
      "THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES AND\n",
      "MOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONS\n",
      "WHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMS\n",
      "OF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINE\n",
      "AT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATES\n",
      "YOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATED\n",
      "BEFORE USIN\n",
      "\n",
      "Successfully read and sanitized Leviathan.txt\n",
      "First 500 characters of cleaned text from Leviathan.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF LEVIATHAN\n",
      "    \n",
      "THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES AND\n",
      "MOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONS\n",
      "WHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMS\n",
      "OF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINE\n",
      "AT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATES\n",
      "YOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATED\n",
      "BEFORE USING THIS EBOOK.\n",
      "\n",
      "TITLE LEVIATH\n",
      "\n",
      "Successfully read and sanitized MobyDick.txt\n",
      "First 500 characters of cleaned text from MobyDick.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF MOBY DICK OR THE WHALE\n",
      "    \n",
      "THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES AND\n",
      "MOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONS\n",
      "WHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMS\n",
      "OF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINE\n",
      "AT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATES\n",
      "YOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATED\n",
      "BEFORE USING THIS EBOOK.\n",
      "\n",
      "\n",
      "\n",
      "Successfully read and sanitized RomeoJuliet.txt\n",
      "First 500 characters of cleaned text from RomeoJuliet.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF ROMEO AND JULIET\n",
      "    \n",
      "THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES AND\n",
      "MOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONS\n",
      "WHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMS\n",
      "OF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINE\n",
      "AT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATES\n",
      "YOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATED\n",
      "BEFORE USING THIS EBOOK.\n",
      "\n",
      "TITLE \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_and_clean_texts(folder_path):\n",
    "    \"\"\"\n",
    "    Reads and sanitizes all text files in the given folder.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): Path to the folder containing the text files.\n",
    "\n",
    "    Returns:\n",
    "    str: Combined and cleaned text from all files.\n",
    "    \"\"\"\n",
    "    all_text = \"\"\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):  # Only process .txt files\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                sanitized_text = sanitizeText(text)\n",
    "                all_text += sanitized_text\n",
    "                print(f\"Successfully read and sanitized {filename}\")\n",
    "                print(f\"First 500 characters of cleaned text from {filename}:\\n{sanitized_text[:500]}\\n\")\n",
    "    return all_text\n",
    "\n",
    "# Path to the folder with text files\n",
    "folder_path = 'Texts/'\n",
    "\n",
    "# Load and clean texts\n",
    "corpus = load_and_clean_texts(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build the Trigram Model\n",
    "\n",
    "### Purpose\n",
    "This function processes the cleaned text to create a trigram model. The model counts the occurrences of each sequence of three characters.\n",
    "\n",
    "### Why is this step important?\n",
    "The trigram model is the core of this task. It represents the structure and frequency of character sequences in the dataset.\n",
    "\n",
    "### Key Details\n",
    "- A dictionary is used to store trigrams as keys and their counts as values.\n",
    "- `defaultdict` is used to handle missing keys automatically.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 trigrams and their counts:\n",
      "THE: 64225\n",
      "HE : 46529\n",
      "E P: 5443\n",
      " PR: 5517\n",
      "PRO: 3571\n",
      "ROJ: 469\n",
      "OJE: 469\n",
      "JEC: 1262\n",
      "ECT: 3300\n",
      "CT : 1852\n"
     ]
    }
   ],
   "source": [
    "def build_trigram_model(text):\n",
    "    \"\"\"\n",
    "    Creates a trigram model by counting the occurrences of each trigram.\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): The cleaned text.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary where keys are trigrams and values are their counts.\n",
    "    \"\"\"\n",
    "    trigram_model = {}  # Initialize an empty dictionary\n",
    "    \n",
    "    # Iterate through the text to extract trigrams\n",
    "    for i in range(len(text) - 2):\n",
    "        trigram = text[i:i + 3]  # Extract three consecutive characters\n",
    "        if trigram in trigram_model:\n",
    "            trigram_model[trigram] += 1  # Increment count if trigram exists\n",
    "        else:\n",
    "            trigram_model[trigram] = 1  # Initialize count if trigram is new\n",
    "    \n",
    "    return trigram_model\n",
    "\n",
    "# Build the trigram model\n",
    "trigram_model = build_trigram_model(corpus)\n",
    "\n",
    "# Display the first 10 trigrams for inspection\n",
    "print(\"First 10 trigrams and their counts:\")\n",
    "for trigram, count in list(trigram_model.items())[:10]:\n",
    "    print(f\"{trigram}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Save the trigram model to a JSON file\n",
    "def save_trigram_model_to_json(trigrams, output_file):\n",
    "    \"\"\"\n",
    "    Saves the trigram model to a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "    trigrams (dict): Dictionary of trigram counts.\n",
    "    output_file (str): Path to the output JSON file.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(trigrams, file, indent=4)  # Use `indent=4` for pretty printing\n",
    "\n",
    "# Save to JSON file after processing all texts\n",
    "output_json_file = 'trigram_model.json'\n",
    "save_trigram_model_to_json(combined_trigram_counts, output_json_file)\n",
    "print(f\"Trigram model saved to {output_json_file}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
